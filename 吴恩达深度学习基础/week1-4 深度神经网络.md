# 深层神经网络

## 深层神经网络

有一些函数，只有非常深的神经网络能学会，而更浅的模型则办不到。

尽管对于任何给定的问题很难去提前预测到底需要多深的神经网络，所以先去尝试逻辑回归，尝试一层然后两层隐含层，然后把隐含层的数量看做是另一个可以自由选择大小的超参数，然后再保留交叉验证数据上评估，或者用你的开发集来评估。

总结下符号约定

输入的特征记做x，但是x同样也是0层的激活函数，所以$x=a^{[0]}$，$a^{[L]}$是这个神经网络预测的输出。

## 前向传播

输入是$a^{[l-1]}$，输出是$a^{[l]}$,缓存是$z^{[l]}$(从实现的角度看缓存的是$w^{[L]}和b^{[L]}$)

**步骤**

$z^{[l]}=W^{[l]}·a^{[l-1]}+b^{[l]}$

$a^{[l]}=g^{[l]}(z^{[l]})$

## 反向传播

输入为$da^{[l]}$,输出为$da^{[l-1]}$,$dw^{[l]},db^{[l]}$